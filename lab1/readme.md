# Лабораторная работа №1 “Линейная регрессия”

## Версия Python
- Python 3.12.1

## Используемые библиотеки
Для выполнения лабораторной работы были использованы следующие библиотеки:
- **NumPy** — для работы с массивами и вычислениями.
- **Pandas** — для загрузки и обработки данных.
- **Matplotlib** — для визуализации данных и графиков.
- **mpl_toolkits.mplot3d** — для построения 3D-графиков.
- **time** — для измерения времени выполнения операций.

---

## Задание
Целью работы было изучение метода линейной регрессии с использованием градиентного спуска и аналитического решения. Основные задачи включают:
1. Применение градиентного спуска для нахождения параметров линейной регрессии.
2. Изучение влияния нормализации признаков и изменения коэффициента обучения \( \alpha \) на сходимость метода.
3. Сравнение результатов градиентного спуска с аналитическим решением методом наименьших квадратов.

---

## Ответы на вопросы

### 1. Нормализация признаков и её влияние на сходимость градиентного спуска
- **Нормализация** признаков существенно улучшает сходимость градиентного спуска. Без нормализации алгоритм сходится медленно и неустойчиво, тогда как при нормализации сходимость становится более быстрой и стабильной.
- Визуализация сходимости показала, что при нормализации функция потерь уменьшается значительно быстрее по сравнению с ненормализованными данными.

### 2. Влияние изменения коэффициента обучения \( \alpha \) на сходимость
- При слишком маленьком \( \alpha \) сходимость алгоритма замедляется, и требуется большее количество итераций для достижения минимума функции потерь.
- При слишком большом \( \alpha \) алгоритм может начать расходиться, что видно на графиках с высокими значениями \( \alpha \).
- Оптимальные значения \( \alpha \) для данной задачи находятся в пределах от 0.01 до 0.1, что дает стабильную и быструю сходимость.

---

## Дополнительные результаты

### Сравнение времени выполнения
- Время выполнения градиентного спуска с векторизацией и без неё было измерено с использованием данных после нормализации признаков. Результаты показали, что векторизация значительно ускоряет процесс вычислений.

- Время (с векторизацией): **X.XXXX секунд**  
- Время (без векторизации): **X.XXXX секунд**

---

## Заключение
- Работа продемонстрировала важность нормализации признаков и выбора правильного коэффициента обучения для эффективного использования градиентного спуска в задаче линейной регрессии.
- Сравнение с аналитическим решением показало, что градиентный спуск сходится к аналогичным результатам, но требует большего времени при большой величине \( \alpha \) или ненормализованных данных.
