**Лабораторная работа №2. Реализация глубокой нейронной сети**

**Данные:**  
В данной лабораторной работе используется набор данных notMNIST, содержащий изображения размером 28×28 с первыми десятью буквами латинского алфавита (A–J). Обучающая выборка включает около 500 тыс. изображений, тестовая выборка – около 19 тыс.

Ссылки для загрузки данных:  
• [Большой набор данных](https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz)  
• [Маленький набор данных](https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz)  
Описание данных доступно по [ссылке](http://yaroslavvb.blogspot.sg/2011/09/notmnist-dataset.html).

---

### **Задания:**

#### **Задание 1. Реализация полносвязной нейронной сети**
Необходимо разработать полносвязную нейронную сеть с использованием библиотеки TensorFlow. В качестве алгоритма оптимизации можно применить стохастический градиентный спуск (Stochastic Gradient Descent, SGD). Требуется определить:
- Количество скрытых слоев (от 1 до 5);
- Количество нейронов в каждом слое (до нескольких сотен);
- Функции активации (ReLU, сигмоида, гиперболический тангенс и др.).

#### **Задание 2. Сравнение с логистической регрессией**
После обучения нейронной сети необходимо сравнить её точность с точностью логистической регрессии. Оцените, насколько улучшились результаты классификации.

#### **Задание 3. Регуляризация и метод сброса нейронов (Dropout)**
Добавьте L2-регуляризацию и метод Dropout для уменьшения переобучения. Проведите анализ: как изменилось качество классификации при использовании этих методов?

#### **Задание 4. Динамически изменяемая скорость обучения (Learning Rate Scheduling)**
Используйте метод изменения скорости обучения в процессе обучения сети. Наилучшая достигнутая точность модели для данного набора данных составляет 97.1%. Оцените, какой результат продемонстрировала ваша модель.

---

### **Реализация**

1. **Загрузка данных**
   - Разархивация данных.
   - Разделение выборки на обучающую, валидационную и тестовую.
   - Проверка сбалансированности классов и очистка от дубликатов.

2. **Предобработка данных**
   - Нормализация изображений.
   - Подготовка меток классов.

3. **Создание модели**
   - Добавление входного слоя.
   - Создание скрытых слоев с указанными параметрами (количество нейронов, функция активации, Dropout).
   - Выходной слой с функцией активации softmax.

4. **Обучение модели**
   - Использование оптимизатора SGD с динамическим изменением скорости обучения.
   - Обучение модели с валидацией на тестовой выборке.
   - Оценка качества модели.

5. **Анализ результатов**
   - Сравнение с логистической регрессией.
   - Оценка влияния регуляризации и метода Dropout.
   - Итоговая точность модели и выводы.

---

### **Вывод**
В ходе работы была реализована глубокая нейронная сеть для классификации изображений набора данных notMNIST. Проведен анализ эффективности различных методов улучшения модели, включая регуляризацию, Dropout и изменение скорости обучения. Полученные результаты позволяют оценить влияние данных методов на точность модели и её способность к обобщению.

